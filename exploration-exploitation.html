
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Optimal Team Size for the Exploration/Exploitation Problem</title>
  <link rel="stylesheet" href="style.css" />
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>
  <div class="container">
    <h1>Optimal Team Size for a Exploration-Exploitation Problem</h1>
    <nav>
      <a href="blog.html">Back to Blog</a>
    </nav>
    <hr />

    <div style="text-align: center;">
      <img src="Colaboration_Caravaggio.png" alt="Collaboration Painting" style="max-width: 800px;" />
    </div>

<!--    <p>Not every project follows the same rhythm. Some are predictable and methodical—you know what needs to be done, and the path is clear. Others, though, are risky. These are the kinds of projects where you don’t know exactly where you’re going until someone has a breakthrough.</p>-->

<!--    <p>Imagine one of those high-risk, high-reward research efforts—the kind where <strong>everyone on the team must publish a paper</strong>, but no one can do so until <strong>someone figures out the big idea</strong> that unlocks the whole project.</p>-->

<!--    <p>There’s a structure to these projects that often goes unnoticed. First comes a moment of <strong>creative insight</strong>—a flash of innovation that reframes the problem or opens a new path. After that, the rest of the team moves into action: applying, testing, writing, and polishing. We might call this second phase the <strong>assembly</strong> or <strong>execution</strong> phase. Everyone gets to work producing their own results, often in parallel, based on the shared idea.</p>-->

<!--    <p>This two-stage structure—first innovation, then execution—is everywhere. And it echoes a well-known distinction in the study of organizations and learning: <a href="https://www.jstor.org/stable/2634940" target="_blank" rel="noopener">Exploration vs. Exploitation</a> </p>-->

    <p> Not every team project are the same, but I want to argue that most of them have two phases. First comes a moment of creative insight that reframes the problem or opens a new path. After that, the team moves into execution: applying, testing, writing, and polishing, often in parallel.</p>
    
<!--    Some are predictable and methodical — you know what needs to be done and the path is clear. Others are riskier: you don’t know exactly where you’re going until someone has a breakthrough.</p>-->

    <p>Consider a high-risk, high-reward research effort in which everyone on the team must publish a paper, but no one can do so until someone unlocks the big idea that makes the project possible.</p>

<!--    <p>These projects often have two phases. First comes a moment of <strong>creative insight</strong> that reframes the problem or opens a new path. After that, the team moves into <strong>execution</strong> — applying, testing, writing, and polishing, often in parallel.</p>-->

    <p>This two-stage structure mirrors the classic distinction in organizational learning: <a href="https://www.jstor.org/stable/2634940" target="_blank" rel="noopener"><em>exploration</em> versus <em>exploitation</em></a>.</p>



<!--    <p>James March (1991) described exploration as the process of searching for new possibilities: experimenting, taking risks, doing something that might fail. Exploitation, on the other hand, is about refining and implementing what you already know: producing results efficiently, capitalizing on what works.</p>-->

<!--    <p>But this structure creates a subtle optimization problem: <strong>how many people should be on the team?</strong></p>-->

    <p> Here I want to explore, with a simple mathematical model, the scaling properties of a task involving these two processes. </p>

    <h2>A Simple Model</h2>

    <p>Suppose you have a group of \( N \) researchers working together. The goal is for each of them to produce something, for example, a publication. However, this is a hard task. To produce a publication they need to have a good new idea. Thus, any publication comes only after a first phase of innovation, followed by putting the new idea/technique in practice. Therefore, we can say that we need first to perform <em>exploration</em> and then <em>exploitation</em>. We assume that the <em>exploration phase</em> (innovation) is the most difficult part of the project, and the <em>exploitation phase</em> (assembling results and publishing for instance) can only start after a successful innovation. 
    <p>Then it cames the question: What is the optimal group size for finishing all steps of a project? </p>  
<!--    All researchers have the same capability to contribute in either phase.-->
    </p>

    <p>Assuming that everyone in the group has the same basic skill, we  can model the time until one person has the innovative breakthrough as an exponential random variable with rate \( 1/d_1 \), so the probability density for one researcher to innovate at time \( t \) is:</p>

    <p>\[
    f(t) = \frac{1}{d_1} e^{-t/d_1}
    \]</p>

    <p>Similarly, we model the time it takes each researcher to produce their own publishable result after the innovation as an exponential random variable with rate \( 1/d_2 \):</p>

    <p>\[
    g(t) = \frac{1}{d_2} e^{-t/d_2}
    \]</p>

    <p>The expected total time to finish the project is the sum of:</p>
    <ul>
      <li>\( T_C \): the time until the first innovation,</li>
      <li>\( T_L \): the time until the last of the remaining \( N-1 \) researchers finishes writing.</li>
    </ul>


    <p>Therefore, \( T_C \) is calculated as the minimum of \( N \) random variables drawn from the \( f(t) \) PDF, thus \( T_C = min \{t_1, t_2, t_3,...,t_N\} \). </p>
    <p>Since the PDF \( f_{min} \) for the minimum of \( N \) i.i.d. is given by</p>
     
     <p>\[
    f_{\min}(t) = N f(t) F(t)^{N-1} = \frac{n}{d_1} e^{-t/d_1} \left(e^{-t/d_1} \right)^{N-1}
    \]</p>
     
     
     <p>Where \( F(t) = \int_t^\infty f(t') dt' \) is the survival probability, and the last term means that one needs that \( (N-1) \) random samples are less than \( t \).</p>
     
     <p> Thus, the expected time to have our first innovation is \( \mathbb{E}[T_C] = \int_0^\infty t' f_{\min}(t') dt' = \frac{d_1}{N}\)</p>
     
<!--     <p>\[-->
<!--    f_{\min}(t) = \frac{n}{d_1} e^{-t/d_1} \left(e^{-t/d_2} \right)^{n}-->
<!--    \]</p>-->

<!--    <p></p>-->





    <p>Now, for \( T_L\) we need to wait for all the remaining \( N-1 \) persons finishing the task. Thus, we have to calculate the maximum of \( N-1 \) random variables from the PDF \( g(t) \), therefore \( T_L = max \{t_1, t_2, t_3,...,t_{N-1}\} \). </p>


    <p>The PDF for the maximum of \( N-1 \) i.i.d. exponential variables with mean \( d_2 \) is:</p>

    <p>\[
    f_{\max}(t) = (N-1) g(t) \big(1-G(t) \big)^{N-1} = \frac{N-1}{d_2} e^{-t/d_2} \left(1 - e^{-t/d_2} \right)^{N-2}
    \]</p>

     
     <p>Here, again, the logic is similar as before. You have the probability of obtaining value \( t \) once, multiplied by the probability that all the remaining \( N-2 \) are smaller than \( t \), given by the term with \( G(t) = \int_t^\infty g(t') dt' \), and all of that can happen \( N-1 \) times. </p>
	


    <p>Then the expected time for the last person to finish is</p>
    <p>\[
    \mathbb{E}[T_L(N)] = \int_0^\infty t \cdot f_{\max}(t) dt \approx d_2 (\ln(N - 1) + \gamma) 
    \]</p>
    <p>where \(\gamma\) is the Euler–Mascheroni constant. <sup id="fnref1">1</sup></p>
    
<!--    <p>^* (This is supposed to be a footnote) To be more precise, the solution for that integral is actualy: \( \sum_i^{N-1} \frac{1}{i}\)</p>-->

    <p>So the expected total time is:</p>

    <p>\[
     \mathbb{E}[T_{\text{total}}(N)] \;=\; \underbrace{\frac{d_1}{N}}_{\text{faster with more people}}\; +\; \underbrace{d_2 \big(\ln(N - 1) + \gamma\big)}_{\text{slower with more people}}
    \]</p>

<!--    <p>The first term decreases with more people: adding researchers accelerates the innovation phase. The second term increases: more people mean more results to finish, and the last person sets the timeline. Therefore the interplay between these two competing process creates a non monotic depedence on \( N \). </p>-->
<p>The first term decreases with \(N\): more people speed up discovery. The second term grows (slowly) with \(N\): more papers must be finished, and the last one sets the final timeline. Their trade‑off creates a <strong>non‑monotonic</strong> dependence<sup id="fnref1">2</sup> on team size, implying an <em>optimal</em> \(N\) that balances faster discovery against longer execution tails. The optimal number of people that minimizes the total time is \( N_{\text{opt}} \approx d_1/d_2\), where we assumed that \(d_1 \gg d_2\) since the inovation/exploration is the most difficult process.  </p>


    <p>The inspiration for this post, comes actually from a different application. It is a result of two works on folding of microstructures. If you are curious you can check  <a href="https://www.nature.com/articles/s42005-020-00423-0" target="_blank" rel="noopener">Communications Physics (2020)</a> and <a href="https://link.springer.com/article/10.1140/epje/s10189-021-00056-3" target="_blank" rel="noopener">The European Physical Journal E (2021)</a>.  </p>


<!--    <p>The same dynamic shows up in software development (where the hardest part might be finding the right architecture), in scientific collaborations (where publishing is the final hurdle), and even in nature. Collective decision-making in animals—from ants to bees—often follows a similar rhythm: someone explores, others exploit.</p>-->

    <hr />
    <section aria-label="Footnotes" style="font-size:.9rem; opacity:.9;">
      <p><sup id="fn1">1</sup> The exact solution is actually \(\mathbb{E}[T_L]=d_2\sum_{i=1}^{N-1}1/i\), the logarithmic approximation is valid for large \( N\). <a href="#fnref1" aria-label="Back to reference">↩︎</a></p>
    </section>
    <section aria-label="Footnotes" style="font-size:.9rem; opacity:.9;">
      <p><sup id="fn1">2</sup> Different models (\(f \), and \(g\)) will lead to different dependences with \( N\) for each process, however it is possible to prove that the total time will always be non-monotonic. <a href="#fnref1" aria-label="Back to reference">↩︎</a></p>
    </section>
    <p style="font-size: small;">&copy; 2025 Hygor Piaget</p>
  </div>
</body>
</html>
